# WEEKLY人工無脳【第5号】（2018.4.30~5.6）

![eye_catch](./../figs/weekly_jinkoumunou.png)


## ゾゾスーツ続報。3Dデータ表示がめっちゃかっこいいんだが。

http://mwwlog.com/life/fashion-life/zozosuite-review.html

さっそくゾゾスーツの使用感レビューブログが出てました。アツいサービスはブロガーが放っとかないのです。

センサーでピッと計測する前バージョンよりも、さすがに計測方法がめんどくさそうです（画像撮影時の注意事項がかなり多そう）。でもそもそも頻繁に撮影するものでもないのでok。
計測結果の3Dデータもめちゃくちゃかっこいいし、測定精度もミリ単位で表示されるようです。計測後はゾゾタウンアプリにデータがリンクされ、商品のサイズ選択時に「あなたのサイズはこれ！」と明示的に教えてくれるそう。もうこれ最高じゃないですか…。絶対自分サイズのシャツ買う。
[マーカーを読み取る技術者](https://gist.github.com/ksasao/bc9c548d5e38932f2d0d11912ba541d0)も既にでてきたぞ。


## AI活用で新たな政治スタイル目指す“ポリテック”の始動

https://this.kiji.is/363304831441732705

小泉進次郎氏が新たな言葉を作って政治に浸透させようとしている。politics × technology。

もう少し詳しい内容も話されているニコニコ超会議でのトーク全編動画はこちら。
https://www.youtube.com/watch?v=MVnFsBsqv5Y&feature=youtu.be

具体的にどういうことをするかということまでは（おそらく時間の都合上）詳しくは言及していないが、まず言葉を作ることが大切だと話している。

銀行業界でFintechという言葉ができたことで、銀行はIT化なりブロックチェーンなり、テクノロジー利用を進めなければいけない（もしくはテクノロジーが必要だ）という認識が広く広まった。
Fintechとは何なのか実際にはよくわからないものであっても「Fintechに取り組み、発展させる姿勢がある」ことを示さなければ会社として世の中に置いていかれるという意識にまで到達したのは記憶に新しい。それを同じようなテクノロジーの意識改革を政治界でポリテックという言葉を使って起こすことがひとまずの目的のようです。
テクノロジーで日本を動かそうとする若手政治家の筆頭として、小泉進次郎氏の発言や行動に注目したい。


## 機械学習は人間が近代までに平均化や最大公約数を得るために振るい落としてきたものを取り戻す武器

https://gigazine.net/news/20180429-ai-machine-learning-sql/

「機械学習とか深層学習なんて小難しいもの使わなくても、正しくビジネス問題の設定ができればSQLだけでも売上は増やせるんや」という話。

ここに書かれていることは正しいのだけど、機械学習が目指してるのは「顧客の上位◯%」「最終購買から◯日」みたいなマス向けのルールベースによるクラスタリングではなく、顧客ごとにコンシェルジュをつけるように、本当の意味でその人だけのオーダーメイドな施策を打てるようにすること。平均化や最大公約数からの脱却を目指すのが機械学習の目標。なのでちょっと話が違う。

（ちなみにタイトルは落合陽一氏がそんなようなことをどこかで言っていたのでその引用）


## 「おじさんの鏡だ」「こんなおじさんになりたい」。”ディープラーニングおじさん”に勇気をもらった人たちが続出。

http://karaage.hatenadiary.jp/entry/2018/05/02/073000

機械学習に詳しくない（というかLinuxもpythonも知らなかった）”おじさん”が半年ほどの独学で深層学習に習熟し、会社のAI事業の方針にも絡むまでになられたお話。「好きこそものの上手なれ、に年齢は関係ない」というのお手本のような話。

インターネットミームでは一般的には「〜〜おじさん」は「時代遅れの老害」を意味してディスる意味の使われ方をするため、それとは真逆の内容に感動した読者が続出。1000はてブ超え。年中ディスで溢れるはてな村に光が指した瞬間である。

https://twitter.com/karaage0703/status/991905828591448065

そしてディープラーニングおじさんが賞賛を集める一方で、[エアポートおじさん](http://news.livedoor.com/article/detail/14659481/)と[TOKIOおじさんたち](https://www3.nhk.or.jp/news/html/20180502/k10011425191000.html)がディスられるGW後半戦の始まり。おじさんたちの戦いはまだまだ続く…


## FBがマッチングサービスを開始

http://www.afpbb.com/articles/-/3173230

個人情報の取扱についてケンブリッジアナリティカ事件の話題も覚めやらぬ中、さらにソーシャル性を強みにしたサービスを打ち出してくるFacebookぐぅ強い。

>米国で結婚するカップルの3組に1組がインターネット上で出会っており、フェイスブックのユーザー2億人が独身と自己申告していることにも言及した。

3組に1組がネットで出会う、ってほんまかいなと。日本のマッチングサービスと何が違うんだ…（それともただのメンタリティー？）

そして類似マッチングサービスの株が軒並み暴落したという…

http://kabumatome.doorblog.jp/archives/65918207.html

個人的には、わりと真剣に少子化対策のためにも日本は国策としてでもネットでの出会いを推奨すべきだと思っている。  
「最大幸福の組み合わせ問題」としてデータサイエンスももっと貢献できるはず。日本では”出会い系アプリ”というネガティブな印象の言葉が残ってしまっていて難しい部分もあると思うが、[Pairs](https://www.pairs.lv/)や[タップル誕生](https://tapple.me/)にもますます頑張って欲しい。


## FacebookはすでにAIの倫理面について考え始めている

https://www.cnet.com/news/facebook-starts-building-ai-with-an-ethical-compass/

かつて画像識別問題において有名だった話だが、”女性の医師”の画像を見せると高確率で”看護師”だと誤判定するということがあった。

この原因は、世の中の医師は一般的に男性が多く、看護師には女性が多いというバイアスを、機械的には男性=医師, 女性=看護師と学習した結果。現実世界では性別・年代による格差や倫理問題は綺麗事抜きにたしかに存在するが、AIには正しくない倫理を学んでほしくない、少なくともFBが今後作るAIにはそういうことを求められている。

そのような課題に対し、FBはアルゴリズムが持つ潜在的な識別バイアスを測定するためのツール”Fairness Flow”を作ったよという話。

ケンブリッジアナリティカの件で、プライバシー情報にセンシティブに成らざるを得ないFBには今、こういった取り組みをアピールする必要性に駆られているのかもしれない。しかしそれは世の中にきっと役に立つことなので応援したい。


## All We Need is arXiv

https://jp.techcrunch.com/2018/05/03/2018-05-01-thousands-of-academics-spurn-natures-new-paid-access-machine-learning-journal/

https://twitter.com/TJO_datasci/status/991989637974343680

Nature紙がなぜか今更有料の機械学習専門論文誌をやりますと言って、「ハゲタカビジネスだ」とボロクソに叩かれている話。

生物学の実験では、依然として専用の設備や機器、高価な試薬が必要な場面が多いので、追試などを誰もが行える環境でない限りは専門の機関（や研究者）が事前にレビューを行ったのちに世に出すプロセスは必要であり、意味がある。（そうしないと真偽不明の論文が大量に出回り逆に研究の足を引っ張ったりして困る）

しかし、機械学習分野においてはGoogleやFacebookが行うような何千台も計算機を並列で走らせるような内容でない限り、自由に動かせるGPUが数台あるだけで多くの人が世界中で各自追試を行うことができる。この環境の違いは「論文の公開プロセス」を全く違う形態にするほど大きな違いがある。

Natureが権威をチラつかせて論文誌を立ち上げたなら、それはかなり時代を読めていないということになる…


## Ng教授のオンライン書籍教材

https://qiita.com/Ishio/items/fae27dfe943195836932

かの有名なNg先生がオンライン書籍を執筆中だそうで、そのドラフト版（1-22章）がオンラインで公開中だそうです。

なんかあっさり書きましたが、そもそも販売する書籍を事前に（ドラフト版といえど）公開するスタイルっていつから普通のことになったんですかね…  
ドラフトを公開することで、ユーザーはいち早く最新のエキサイティングな内容に触れるし、著者は内容や誤字、感想のフィードバックを貰える。そして公式公開までアジャイルに直していく…。人々の意識もかなり代わりましたね...スゴイ時代になったものです…

上の論文紙の話題とも一部通じますが、機械学習関連の論文や技術解説文書はもはや現在の一般的な出版スタイル・意識・スピード感と大きな乖離があります。  
技術はすぐに陳腐化する。これは慣用句ではなく、早いと3ヶ月〜半年でも十分に”昔”の話になってしまう。

書籍レベルのまとまった情報でなくても、noteでサクッと最新の話題を書いて、1月ほどの賞味期限内（実際に期限なんて無いが、気分的にはそんな感じ）に買ってもらうという意識が何となくあるし、最近話題の[マッハ新書](https://booth.pm/topics/mach_digital_paperback)のような、もはやちんたら200ページを文書を読むことなく箇条書きで超サックリと要点だけ話すような文書スタイルもじわじわと流行り始めている。

技術者の副業意識も高まりつつある背景もあり、この流れはまだまだ大きくなりそうな気がする。
話が逸れたが、機械学習分野の進歩の速さは当該の技術分野だけに留まらず、出版業界にも影響を与えているという話がしたかった。


## FBのコンピュータービジョン精度向上は、ユーザーの思い出でをより鮮明に記録してくれる

http://thebridge.jp/2018/05/facebook-is-using-instagram-photos-and-hashtags-to-improve-its-computer-vision

タイトルが全てを要約してくれている。ちなみに原文は[こちら](https://venturebeat.com/2018/05/02/facebook-is-using-instagram-photos-and-hashtags-to-improve-its-computer-vision/)

画像認識はすでに驚くような精度で詳細なジャンルまで識別できるようになっているがこの進化はまだまだ止まらない。

これ以上精緻に、精度良く識別できる必要があるのかしらと個人的には思ったりするが、FBにおいてはユーザーが投稿する画像に映るものが「白いスーツを着た男」ではなく「ピエロ」だというところまで認識できることによって、ユーザーの思い出をより鮮やかに記録することができるようになる。それは素晴らしいことだと思う。

[2012年にFBがinstagramを10億ドルで買収した](https://jp.techcrunch.com/2012/04/10/20120409facebook-to-acquire-instagram-for-1-billion/)ときには流石にこういったデータの使い方をするとは想定してなかっただろう。FBは良い買い物をしたんだなー。

ちなみに、インスタグラム画像への教師情報にはタグ情報を用いているそうで、それはそれでタグのノイズ問題がある（画像に映ってもないのにノリで関係無いいろんなタグを多量にくっつける人いますよねー）。  
その問題には、弱い教師あり学習（Weakly supervised learning）なるもので対応させているらしく気になる。
現状で2万カテゴリの分類が可能になり、将来的にはこれを10万まで増やす予定だそうです。


## 2万円台のスタンドアローン型VRヘッドセットが本物のVR布教起爆剤となるか

https://japanese.engadget.com/2018/05/01/2-vr-oculus-go-pc/

おそらく今週のIT業界で最もインパクトがデカかったニュースではないだろうか。

「このブログの趣旨と関係ないじゃん」と言われそうだが、オンラインコニュニケーションの主戦場が遅かれ早かれ確実にVR/AR空間に移っていくなかで、AI的な技術は必ずその中心にいることになるので関係なくない（たぶん）。

今回のOculus Goは値段を安価にするためにも、モーションに関するセンシングは制限しているらしい。

>上下左右を見渡す・見上げる・見下ろすことはできますが、しゃがんで下から見たり、頭や体を動かして避けるような動きには対応しません。

それでもなお、「安価で、取り回しの容易な」デバイスが圧倒的な”正義”であることには変わりない。
GWにすでにガチャガチャと触っているアーリーアダプターなエンジニアたちは[Oculus Goで怠惰にNetflixを楽しんだり](https://www.moguravr.com/netflix-oculus-go/)している。くそぅ、羨ましい…

VRと深層学習といえば、ICLR2018のbest paperに選ばれた論文「[Spherical CNNs](https://arxiv.org/abs/1801.10130)」がある。球形画像にCNNかけるという内容。


## 理論が先か、データが先か。でも二律背反は良くないよという話。

http://d.hatena.ne.jp/himaginary/20180504/Andrew_Haldane_will_big_data_keep_its_promise

つまり推論の方法、「演繹法」と「帰納法」の話をしている。

経済学者は主には演繹法的な考え方、データサイエンティストは帰納法的な考えが中心にあるよね、という話。  
[演繹法と帰納法](https://matome.naver.jp/odai/2139625697364840601)は、ざっくりいうと、物事を考える際に「理論（ルール）」が出発点になる考え方なのか、「現実（データ）」が出発点になる考え方なのかということ。

もちろん、演繹法を主とする経済学者が、考え方の違いによって二律背反的に帰納法を主とするデータサイエンティストをディスっているという話ではなく、経済学者は長い歴史の中で「統計も嘘をつく」事をよく知っているので、帰納法的なやり方に偏重した推論は危ないよ、データサイエンティストの人は気をつけてね、という感じ。  
この手の話もわりと定期的に盛り上がっているような気がする。この話はちょうど次の記事の話にもリンクする。


## Netflixは定性分析と定量分析をいい感じに行う。（でも「定量>定性」な気がする）

https://qiita.com/KanNishida/items/12f9ae0cee98fd54b0bb

泣くデータサイエンティストも黙るNetflix様の分析事例紹介記事。誰もが知るコンテンツデータ分析の神様的企業である。

Netflixのデータ活用事例と言えば、レコメンデーションの精度がめちゃくちゃ良いという話が多く世に出ていますが、この記事ではレコメンド以外のデータに基づく施策判断事例・リテンション（ユーザーの契約継続率）を下げない/上げる施策が紹介されておりすごく興味深いです。（個人的には5つ星評価方法をやめた話が面白かった）

ただ単に、「圧倒的なデータ量を武器に定量的な分析を行ってリテンションを下げない/上げる施策を決めていますよ」という話ではなく、アンケートや個別のユーザーインタビューから収集する定性的な評価も大いに参考にしているという話もしています。あと、とんでも無い数のA/Bテストをやりまくっている感。

1つ上の記事の話も兼ねて考えるなら、演繹的な方法（Netflixの中の人達が正しいと考えている仮説やユーザーからのサービスに対する改善要望など）からの結果だけでなく、データからの帰納的な根拠も一致しないと本サービスとして実装しない、というような話。  
ただし、記事を読んでいる感じでは、「ユーザーがYesと言っても、データがYesと言わなければやらない」「データがYesと言ってて、ユーザーもYesだったら納得感あるからやる」というような、どちらかといえば定性的な評価よりも定量的な評価に重きが置かれているようにも感じる。。。

「バランス良くいろいろな視点・手法で分析しようぜ、だってそれぞれのやり方には弱点があるのだから」、ということを以下の文章が説明してくれてます。

>既存のデータを使った分析は今日起こっていることを理解するのにはいいですが、将来のことを理解することができません。クオリテイティブやアンケートの手法に関しては、カスタマーはインタビューやアンケートでは本当のことを言ってくれないということが分かっています。そして、A/Bテストに関しても、そもそもそうしたテストができないようなケースがたくさんあります。

と言いつつ、既存のデータを使って”将来ウケるコンテンツ”を作りまくっているNetflix様でした。