# WEEKLY人工無脳【第8号】（2018.5.21~5.27）

![eye_catch](./../figs/weekly_jinkoumunou.png)


## ① 五万回くらい頷いたし、全ページニヤニヤが止まらないので分析官は電車閲覧注意なスライド

https://docs.google.com/presentation/d/192wLLgNzkbwuJ8gLwu_SJMigwxg_EZrYeaK8vBoz3_I/edit#slide=id.p

分析案件あるあるなスライド。完全なアリよりのアリでマジ卍すぎて苦笑がとまらない。

[@chezouさん](https://twitter.com/chezou)によるkawasaki.rbでの発表資料。
[機械学習工学研究会](https://medium.com/@chezou/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%B7%A5%E5%AD%A6%E7%A0%94%E7%A9%B6%E4%BC%9A%E3%82%AD%E3%83%83%E3%82%AF%E3%82%AA%E3%83%95%E3%82%B7%E3%83%B3%E3%83%9D%E3%82%B8%E3%82%A6%E3%83%A0%E3%81%AB%E7%99%BB%E5%A3%87%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F-f7bf36707346)で話足りなかったことを話されたスライドのようです。機械学習工学会のスライドとの落差が好きです。

個人的に一番笑ったのは、
>「我が社はデータが山のようにあって」
>「はいはい、MySQLに1億レコードね」


## ② いろんなGAN

https://twitter.com/hardmaru/status/998780024005189632?s=12

https://twitter.com/prostheticknowl/status/998663860746948608?s=12

ラーメン二郎生成といえば[@knjcode](https://twitter.com/knjcode)ですね。もはやラーメン屋。

それにしてもGAN生成の連続画のゾワゾワする感じはなんなんでしょうか…悪夢っぽい。

どうでもいんですが、twitterの縦に流れるUIって、こういったショート動画載せるには一覧性やお手軽さ的に最強のメディアだと思うのです。ユニークなGAN動画があつまるハッシュタグとかあればちょっとしたアート作品になりそう。


## ③ 画像認識を使った麻雀支援アプリが良さそう

https://mj-news.net/game-app/2018052198280

東北大学の学生5名チームが、学生向けハッカソン「JPHACKS2017」で麻雀支援アプリを作成し、審査員特別賞の他4つの企業賞を同時受賞した話。麻雀牌の画像認識には機械学習が使われているっぽい。

完成度は高そうですが、現在は一般にリリースされているわけではないようです。めちゃくちゃ大きなニーズとまではいかなくても確実なニーズはありそう。

牌の画像認識をどうやっているのか技術詳細は不明ですが、SSDで牌の検知を試みた[こちら](http://blog.brainpad.co.jp/entry/2017/11/07/140000)の記事によると、牌中に繰り返し現れる構造などもあり、単純には難しい模様。また、牌のデザインは製品によって微妙に異なると思われるので、そのへんをどこまでカバーできているのかも気になるところです。


## ④（悲報）新たに「共感モデル」が搭載されたりんな氏、既読スルーを覚える

https://pc.watch.impress.co.jp/docs/news/1123294.html

りんなに新しいモデルが搭載され、「新しい話題を切り出す」「質問する」「相手の発言を肯定する」「相づちを打つ」が出来るようになったらしい。マジかよだいたいのコミュ障を越えたじゃん！！！

>「共感モデルは、できるだけ相手と長く会話を続けるのが目的である。会話の目的を意識して、戦略的に自分の返答を生成することを目指すことになる。これまでは、一度学習したものをベースに、脊髄反射のような反応していたが、過去のセッションの状況と、いまやってきた変動内容を加味して返事をするようにしている」

そんな難しいことが現状の自然言語処理技術でできるのか…ということで、実際に自分でもりんなと会話していろいろ試してみたところ、それほど前とは変わらないようにも感じる。。。

[第6号](http://ysdyt.hatenablog.jp/entry/week6)にもあったGoogleのDuplexは、「予約に関する電話会話」に特化させて学習することであそこまで自然な応答を可能にしていますが、りんなのように「自然会話」を成立させるのは段違いに難しいですね…。そもそも我々が何を持って雑談を「自然」だと思っているのか、定義も難しいですし。

なお、共感獲得の末、嘘か真か既読スルーも覚えた模様。機械にも無視される人類。
https://twitter.com/ikeay/status/999128235085463553



## ⑤ 今週のドジっ子Alexaちゃん話

http://www.itmedia.co.jp/news/articles/1805/25/news071.html

http://www.itmedia.co.jp/news/articles/1805/23/news088.html

Alexaのオチャメ（？）な誤処理話について。
2つの記事はそれぞれ、

1. 「アレクサ」という音を自分に向けたコマンドと誤認して処理をスタート -> 処理待ち状態のところに、意図していないアクションを指示したかのように処理されてしまった。
2. オウムが話した言葉を人間からの指示として処理した
という原因のようです。

1についてのアマゾン側見解は、

>「Alexa」のように聞こえる音声で起動したEchoがその後の会話の中で「メッセージを送信」と命令されたと受け取ってしまい、その段階でAlexaは「誰に？」と尋ねたが、続いている会話の中からユーザーの連絡先リストにある人の名前を聞いてしまったと説明した。

「そんなことある？」って感じだし、2に関しては絶対オウムネタやる人出るやん…と思ってましたが、とにかく、スピーカーへの音声コマンドトリガーがまだまだ技術的にも運用的にも発展途上のために起こったようです。

明示的にコマンドのスタートワード（「ねえぐーぐる」や「あれくさ」）を教えてあげること自体がそもそも面倒であるものの、でもそれをしないと技術的には音声コマンドを受け取ることが難しい。それぞれを解決するには、

1 -> 会話の文脈を理解しないといけない。自分に向けた発話なのか、自分以外の人への発話なのか。
2 -> 命令を発しうる人（家族とか）の音声別識別ができないといけない。登録者以外の命令は受け付けない。

Alexaの目となるもの（室内画像のデータもインプットに追加するなど）があれば話はまた違うのでしょうが、音声だけでもそれぞれの技術的な課題の解決は時間の問題という気もするのでAlexaちゃんが賢くなる日を待ちましょう。（きっとすぐ追いついてくれるハズ）


## ⑥「Data engineers」「data scientists」、そして「MachineLearning Engineers」の棲み分け

https://medium.com/moonshot/ataengineers-vs-data-scientist-13fce30812a7

『「データサイエンティスト」と「データエンジニア」は仕事の領分も必要スキルも違うのでちゃんと分けて考えような』ってお話。海外記事の和訳記事。

「データサイエンティスト」と「データエンジニア」の区別はまだまだ道半ばな感じですが、でも実際どう違うの？ってことをいい感じに言語化してくれている記事です。良い記事なんですが、なんでタイトルが「vs.」ってなってるのかは謎。二項対立戦争はダメってエディター戦争のときに約束したでしょ！！！

データ分析とシステム構築はもちろん分けてやったほうが良いのですが、データ分析官ももはやシステム構築や処理に関する知識がないと分析用のデータを取り出すことすらできない場合もあるというのもまた事実。
自分の周りの分析官にも「最近なに勉強してますか」と聞くと「システム構築周りのこと」と答える人も少なくない感じです。そして勉強熱心な分析官は実際にシステム構築周りのことにも興味があるので、結局は「デキる分析官」がシステム構築にも携わっているなんてこともアルアルかもです。


## ⑦ またメルカリデータ分析チームの記事…悔しいけど欠かさず読んでる…

https://webtan.impress.co.jp/e/2018/05/22/29205

アナリティクスサミット2018で登壇されたメルカリの分析部のトークについてのまとめ記事。

メルカリの分析部は、この数ヶ月だけでもかなり積極的に情報公開・発信されていて、サービス規模に対して7人という少人数チームながら事業会社の分析チームとしてはすでに確固たるポジションを築いている気がします。
会社のデータを見る仕事なのでなかなか外部に向けて発信しにくいはずですが、「分析哲学」や「採用基準」などの話も混ぜ込んだり、さまざまなことがロジカルに整理され言語化されているので「ためになるなー」感がすごいです。

なんだかかっこよくて悔しいのであまりメルカリ関係の記事読みたくないのですが、TLに流れてくるたびに我慢できずに踏み、「ぐぬぬ」と思いながら読み、「良い記事だった…」と閉じることを繰り返しています。悔しい…！

メルカリ関係の直近の記事は、[第1号](http://ysdyt.hatenablog.jp/entry/week1),[2号](http://ysdyt.hatenablog.jp/entry/week2),[3号](http://ysdyt.hatenablog.jp/entry/week3),[7号](http://ysdyt.hatenablog.jp/entry/week7)にもありますのでメルカリファンの方はどうぞ。

さらに余談ですが、メルカリさんはpodcastもやっていて、[分析マネージャー樫田さんが話されている回](http://mercan.mercari.com/entry/2017/02/01/120000)（※2017年2月公開なのでちょっと古い）もあります。


## ⑧「あなたにとっての報酬はなにか？」がいつか機械学習でバレる時代がくる…？

https://news.mynavi.jp/article/20180523-633970/

これは面白いやつ。

逆強化学習によって線虫（C. elegans）における行動時系列データから、線虫の「報酬」が何かを推定したという京大の研究結果について。推定された報酬を用いて線虫行動をコンピュータでシミュレーションした結果でもモデルの妥当性が確認されたそうです。

強化学習と逆強化学習の違いは、
>強化学習は、どの状況でどれくらい報酬を得られるのかはあらかじめ決められており、試行錯誤によって得られる報酬を最適化する行動戦略を見つけ出すことが目的とするもの。一方の逆強化学習では、動物はすでに最適な行動戦略を獲得しているとして、計測された行動時系列データから未知の報酬を推定することが目的になる。

研究の目的は、
>線虫がどのような戦略にしたがって行動しているのかはこれまで謎だった。そこで同グループは、線虫を温度勾配においてトラッキングすることで、行動時系列データを取得し、逆強化学習法により、線虫にとって何が報酬となっているのかを推定した。

結果的には、良い感じに計算モデルによって線虫の行動戦略がバレてしまったようなんですが、さて、人間はどうなんでしょう…

我々は自由意志と理性によってさまざまな選択を行い、それぞれに個性を発揮して自由に生きているはずですが、いつかAI的なものが我々の膨大で詳細な行動ログなどを解析できる時代がくれば、実は全員が少数の特定の「報酬」を目指して生きていることが判明したら…。SF映画化待ったなし。


## ⑨ 虫でpose estimation

CNNによるfast animal（動きが早い動物）のpose estimation。論文ではハエとマウスでの結果例が紹介されている。

https://twitter.com/casa_tuthill/status/1000038636983758848

まだ中身は読めていないけど、線虫の話を読んでいたときにTLに流れてきたのでアイキャッチ負け（ジャケ買い的な意味）してリンクを踏んでしまったやつ。推定動画がなんかかわいい。